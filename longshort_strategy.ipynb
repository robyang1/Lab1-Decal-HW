{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330f5735",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"longshort_strategy.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efbb5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce7db535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isclose(value, original, tolerance= 0.05):\n",
    "    return value <= original * (1+tolerance) and value >= original * (1-tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5390a7",
   "metadata": {},
   "source": [
    "In this homework, we will:\n",
    "- Introduce pandas through data cleaning and processing.\n",
    "- Implement a basic trading strategy.\n",
    "- Model the costs of a trading strategy.\n",
    "- Calculate expected returns.\n",
    "- Use expected returns to create a trading strategy.\n",
    "- Try to add predictive features/signals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e00eb42",
   "metadata": {},
   "source": [
    "# Pandas intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ac396",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c10245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of sp500 companies, from wikipedia\n",
    "url = 'https://en.m.wikipedia.org/w/index.php?title=List_of_S%26P_500_companies&oldid=1219339331'\n",
    "\n",
    "# pandas lets us read html tables from wikipedia page\n",
    "data = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfd0b73",
   "metadata": {},
   "source": [
    "You can add cells in the notebook to perform quick operations or tests. Note that the last value in a cell will automatically be displayed below the cell once it finishes running. Let's examine the type of variable that `data` returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a0119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f82307c",
   "metadata": {},
   "source": [
    "We can access values in a list using indexing and slicing operations:\n",
    "\n",
    "- `list[i]` will return the \\(i\\)-th value in the list, starting with 0.\n",
    "- `list[i:]` will return the \\(i\\)-th value and onward.\n",
    "- `list[:i]` will return all values up to the \\(i\\)-th value.\n",
    "- `list[i:j]` will return values from the \\(i\\)-th value onward, up to but not including the \\(j\\)-th value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23b6bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like data returns a list of tables, what type is each table? \n",
    "type(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ec3c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataframe is the core object of pandas, we'll abbreviate as df\n",
    "# a dataframe is essentially a code version of a table\n",
    "df = data[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb016bee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can look at the first n rows of a table using df.head(n)\n",
    "# please do so here\n",
    "df_head5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e03ea741",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4474a4",
   "metadata": {},
   "source": [
    "In this analysis, we are not particularly interested in the columns for security, headquarters, date added, founded, or CIK values. We can select specific columns of a DataFrame by passing a list of column names:\n",
    "\n",
    "```python\n",
    "columns = ['colname1', 'colname2', ...]\n",
    "df[columns]\n",
    "```\n",
    "\n",
    "Please select every column except for security, headquarters, CIK, founded, and date added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a6ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965990c2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c7da8",
   "metadata": {},
   "source": [
    "It appears there are quite a few sectors! In a DataFrame, one column is referred to as a series. We can select a series using `df['colname']`. By using `series.unique()`, we can obtain a list of the unique values within a series.\n",
    "\n",
    "Please return the number of unique values in the 'GICS Sector' column. Note that you can programmatically access the length of this array using `.size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4ef579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_sectors = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a4ed6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e0328a",
   "metadata": {},
   "source": [
    "If we want to determine how many times each unique value appears in a series, we can use `series.value_counts()`. This function associates each unique value with the number of times it appears in the series.\n",
    "\n",
    "Please return the number of times 'Information Technology' appears in the 'GICS Sector' column. Note that you can programmatically access the count for 'Information Technology' using `series.value_counts()['uniquevalname']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b302c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "it_sectors = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63a92a1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab98d193",
   "metadata": {},
   "source": [
    "One way to select values from a DataFrame is by using index-based location, or `iloc`. We can use `df.iloc[index for rows, index for columns]` to specify which indices to select.\n",
    "\n",
    "- `df.iloc[:,:]` will return the entire DataFrame.\n",
    "- `df.iloc[:5, :6]` will return the first 5 rows and 6 columns.\n",
    "- `df.iloc[2:5, 3:]` will return the third column and onward, for rows 2-4.\n",
    "\n",
    "Please return rows 5-9, and return the 2nd column and onward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500397e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "specified_slice = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d391d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ff141",
   "metadata": {},
   "source": [
    "We can also examine the sub-industries, each of which is associated with one of the sectors. To select only the rows of the DataFrame that correspond to a specific sector, we can use boolean indexing.\n",
    "\n",
    "A boolean operator can be created generally using `df['colname'] {comparator} {value}`. This returns a series of `False` and `True` values for each row.\n",
    "\n",
    "Please create a boolean operator for when the 'GICS Sector' is 'Health Care' and return the number of `False` values using `value_counts()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a0ca1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "false_healthcare = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f722ffee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dfcdb9",
   "metadata": {},
   "source": [
    "Now that we have our boolean operator, we can select the values that are `True`. We do this using `df[operator]`, where `operator = df['colname'] {comparator} {value}`.\n",
    "\n",
    "Please use the operator you created to select only the rows where the security is in the 'Energy' sector (using the 'GICS Sector' column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01461b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc723e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4704f7",
   "metadata": {},
   "source": [
    "We also have `df.loc`, which works similarly to `df.iloc`. Here are some examples:\n",
    "\n",
    "- `df.loc[row_indexer, column_indexer]`\n",
    "- `df.loc[start_row_label:end_row_label, start_col_label:end_col_label]`\n",
    "- `df.loc[list_of_row_labels, list_of_column_labels]`\n",
    "- `df.loc[boolean_array_for_rows, boolean_array_for_columns]`\n",
    "\n",
    "Please select the rows where the 'GICS Sector' is 'Industrials', and return the 1st through 4th columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb1d5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first4cols_industrials = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36320044",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea2013",
   "metadata": {},
   "source": [
    "Another useful DataFrame operation is sorting. We can sort an entire DataFrame using `df.sort_values('colname', ascending=True/False)`.\n",
    "\n",
    "Please sort, in ascending order, the symbols in the 'Consumer Discretionary' sector, and report the 4th oldest security (by date added). You may want to break this into three separate tasks to make it easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fc74e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "old_4_security = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21fe660",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdb8cf2",
   "metadata": {},
   "source": [
    "Let's also introduce the `groupby` operator. We can group a DataFrame based on a given column, such as the 'GICS Sector' column. After grouping a DataFrame, we commonly apply some kind of aggregation, such as a count, an average, etc. For example, we might use `df.groupby('colname').count()`.\n",
    "\n",
    "Please return the average CIK number of the 'Real Estate' sector using the `df.groupby('colname').mean(numeric_only=True)` aggregation. You can also access a specific series by adding `df.groupby('colname1').mean(numeric_only=True)['colname2']` to view the aggregation of a particular series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffc52e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_realestate_cik = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a570f0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_subindustry(df):\n",
    "    # .index returns the index of a series, in this case the unique values\n",
    "    # since value counts is sorted in descending order\n",
    "    # .value_counts().index[0] will give us the largest avlue\n",
    "    \n",
    "    # we can also use display to show the intermediate steps\n",
    "    # we use series.values to access the list of values in the series\n",
    "    \n",
    "    print('-'*35)\n",
    "    print(df['GICS Sector'].values[0])\n",
    "    print('-'*35)\n",
    "    display(df['GICS Sub-Industry'].value_counts())\n",
    "    return df['GICS Sub-Industry'].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GICS Sub-Industry'].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aece24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('GICS Sector').apply(get_common_subindustry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc71288",
   "metadata": {},
   "source": [
    "# data downloading/cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa0bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the yfinance library provides access to lots of information about tickers available on yahoo finance\n",
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be9152bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6304623d",
   "metadata": {},
   "source": [
    "**Errors are expected as data is missing for some tickers, see the future cells!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2b01f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can download historical price data for these assets using\n",
    "# yf.download(tickers)\n",
    "# there's other optional parameters that we won't cover here\n",
    "# lets get the list of symbols/tickers we care about, and then download them using .unique() on our dataframe\n",
    "# convert the series to a list before you pass it to yf\n",
    "# this may take a minute or two\n",
    "# please put the data into a dataframe called hdf, or historical dataframe for short\n",
    "\n",
    "tickers = list(df['Symbol'].unique())\n",
    "hdf = yf.download(tickers, start='2023-10-01', end='2024-03-29')\n",
    "hdf = hdf[hdf.index <= '2024-03-19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76f42e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a186f5",
   "metadata": {},
   "source": [
    "Let's take a look at the data we've just downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3210e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "516e1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like the index is the date, and we have multiple levels of columns!\n",
    "# we can get the top level of columns using df.columns.get_level_values(i)\n",
    "# let's look at the unique top level columns, with .unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46003865",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf.columns.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cbbb3b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the first level of columns has the 'adjusted close', or the closing price for that day, with interest rate adjusted\n",
    "# we are also given 'volume', or the amount of shares traded that day\n",
    "# the other stuff might be nice to have, but we'll just stick with adjusted close and volume for simplicity\n",
    "# let's now select those\n",
    "# to not destroy our old dataframe, we'll make a copy called hdf_raw with df.copy()\n",
    "# once you make the copy, make hdf = hdf[columns]\n",
    "hdf_raw = hdf.copy()\n",
    "hdf = hdf[['Adj Close', 'Volume']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62fba96",
   "metadata": {},
   "source": [
    "2b or not 2b, the answer is not because I deleted the question :) Also, **the next cell is filled in for you, so there's nothing you need to do here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28ef6703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# you may have seen the following error message upon download: \n",
    "\n",
    "# 2 Failed downloads:\n",
    "# - BF.B: No data found for this date range, symbol may be delisted\n",
    "# - BRK.B: No data found, symbol may be delisted\n",
    "# - GEV and SOLV are also recent additions without any data\n",
    "\n",
    "# please use df.loc to view the data for these symbols\n",
    "# you should return all rows, and use columns.get_level_values(1) to get the second level of columns, with the symbols\n",
    "# note that you can use '.isin(list)' as a boolean operator to return if a value is in a list\n",
    "# your code might look like\n",
    "\n",
    "# df.loc[:,df.columns.get_level_values(1).isin([list of values to check])]\n",
    "broken_df = hdf.loc[:,hdf.columns.get_level_values(1).isin(['BRK.B', 'BF.B', 'GEV', 'SOLV', 'PXD', 'WRK', 'CTLT', 'MRO'])]\n",
    "broken_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea789d1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220a69d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# awesome, now lets select everything except for that, since we dont want to use this data\n",
    "# we can invert a boolean indexer by using ~, eg. df.loc[:, ~<condition>]\n",
    "# let hdf be equal to this new selection, and then drop nan values using df.dropna()\n",
    "hdf = \n",
    "hdf = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0460f2d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74be3a38",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Please also check gradescope for any written assignments for this week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f07a31",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cce917",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(df_head5) == 5\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(columns) == 3\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert unique_sectors == 11\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1d": {
     "name": "q1d",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert it_sectors == 65\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> it_sectors\n65",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1e": {
     "name": "q1e",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert specified_slice.shape == (5,6)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1f": {
     "name": "q1f",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert false_healthcare == 439\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1g": {
     "name": "q1g",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert energy['CIK'].sum() == 19373487\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1h": {
     "name": "q1h",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert first4cols_industrials.shape == (79,4)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1i": {
     "name": "q1i",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert old_4_security == 'Bath & Body Works, Inc.'\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1j": {
     "name": "q1j",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(mean_realestate_cik, 956436.7741935484)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert hdf.shape == hdf.shape\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert hdf.columns.size <= 1006\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2c": {
     "name": "q2c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert broken_df.shape[1] >= 12\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2d": {
     "name": "q2d",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert hdf.shape[0] == 115 and hdf.shape[1] <= 500\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
